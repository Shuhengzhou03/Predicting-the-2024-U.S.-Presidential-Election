---
title: "Forecasting a Lead for Kamala Harris in the 2024 U.S. Presidential Election"
subtitle: "The Role of Pollster Transparency, Regional Dynamics, and Key Predictors in Shaping Voter Support"
author: 
  -Jiaxuan Song
  -Zien Gao
  -Shuheng (Jack) Zhou
thanks: "The GitHub Repository containing all data, R code, and other files used in this project is located here:<https://github.com/Shuhengzhou03/Predicting-the-2024-U.S.-Presidential-Election.git>"
date: today
date-format: long
abstract: "We analyze the 2024 U.S. presidential election using Bayesian generalized linear models on aggregated polling data, focusing on predictors such as pollster transparency, state, and poll quality. Our models predict that Kamala Harris is likely to lead with an average support of 47.34%, with her support positively correlated with higher transparency scores among pollsters. In contrast, Donald Trump’s support remains relatively stable across poll transparency levels. State-level predictions highlight close competition in pivotal swing states, including Pennsylvania and Michigan, underscoring their decisive influence on the election outcome. This analysis demonstrates how transparency and geographic factors shape voter sentiment, offering insights to inform future election forecasting."
format: pdf
number-sections: true
toc: true
bibliography: references.bib
---


```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(palmerpenguins)
library(rstanarm)
library(modelsummary)
library(janitor)
library(arrow)
library(ggplot2)
library(knitr)
# Load the dataset
data <- read_parquet(here::here("data/02-analysis_data/us_polling_cleaned_data.parquet"))
```

\newpage

# Introduction

As a superpower with extensive global influence, the United States asserts its position through its economic strength, military power, diplomatic influence, and contributions to technology and culture [@zakaria1999wealth]. Therefore, the 2024 U.S. presidential election has attracted worldwide attention, as the outcome of this election may profoundly impact global affairs. As of October 2024, the U.S. presidential election has entered a crucial phase. Current Vice President Kamala Harris (Democrat) and former President Donald Trump (Republican) are locked in an intense race for the presidency, with competition particularly focused on key swing states like Pennsylvania, Georgia, and Michigan, where the outcome could sway the entire election [@walker2023forecasting]. President Biden has shown strong support for Harris, urging voters to turn out and cast their ballots to help Democrats retain control in both the House and Senate as well as the presidency [@enns2024understanding]. As candidates from the Democratic and Republican parties contend for the highest office, understanding and predicting electoral outcomes has never been more crucial. Polling data, and capturing snapshots of public opinion across various demographics and regions, plays an essential role in forecasting these outcomes. However, variations in sample recruitment and pollster transparency can affect individual poll polls' reliability. To enhance the robustness of our predictions, this study employs a Bayesian generalized linear modelling approach that incorporates aggregated data from multiple polling sources, collectively known as “poll-of-polls.” This approach enables more accurate forecasts by accounting for uncertainties inherent in each poll.

The primary estimate of this study is the predicted percentage of support each candidate—Kamala Harris and Donald Trump—is expected to receive in individual polls leading up to the 2024 U.S. presidential election. This support percentage (pct) serves as a continuous outcome variable, representing the proportion of respondents in each poll who favour a given candidate. By modelling pct, we capture support at the poll level, which can then be aggregated across all polls to forecast overall election outcomes. The Bayesian generalized linear approach enables us to incorporate prior distributions and update predictions as new polling data becomes available, enhancing our ability to account for the uncertainty in each poll. To further refine our predictions, we incorporate predictor variables such as pollster reliability scores and transparency measures, adjusting for poll quality and thus providing a more accurate estimate of each candidate’s expected support.

Our analysis using Bayesian generalized linear models reveals several key insights into the factors influencing predicted support for Kamala Harris and Donald Trump in the 2024 U.S. presidential election, ultimately predicting Harris to have a slight lead with average support of 47.34%. Transparency score emerged as a significant predictor, with Harris’s support showing a positive correlation with higher transparency ratings among pollsters, suggesting her supporters may place greater trust in transparent polling sources. In contrast, Trump’s support was less impacted by transparency, indicating a potential difference in how each candidate’s base interacts with polling reliability. Pollster numeric grade also influenced model precision, with high-grade pollsters yielding narrower prediction intervals, underscoring the reliability of these sources. At the state level, predicted support patterns align with historical voting trends, with Harris favoured in Democratic-leaning states like California, while Trump shows stronger support in Republican strongholds such as Texas. However, in pivotal swing states such as Pennsylvania, Michigan, and Georgia, the models reveal tight competition, reflecting the heightened significance of these regions in determining the election outcome. This analysis highlights the importance of transparency and geographic factors in understanding voter sentiment and refining election predictions.

Predicting the outcome of the U.S. presidential election holds significant importance not only for political parties but also for public stakeholders, analysts, and international observers. The Democratic Party emphasizes that this election impacts more than just the presidency; it holds significant implications for congressional power and will influence America’s future direction in areas such as the economy, social policy, and foreign relations [@gelman1993american]. An accurate forecast model can offer valuable insights into shifts in public sentiment, highlight critical factors influencing voter behaviour, and provide strategic guidance for campaign efforts. Furthermore, understanding the limitations and strengths of polling data helps to reinforce or caution against certain predictive approaches, ultimately contributing to the field of political science and electoral studies.

# Data {#sec-data}

## Overview
In this project, we utilize the statistical programming language R [@citeR], along with essential packages including tidyverse [@tidyverse], palmerpenguins [@palmerpenguins],knitr[@knitr2014], rstanarm [@rstanarm], modelsummary [@modelsummary], janitor [@janitor], arrow [@arrow], and ggplot2 [@ggplot2]. Our data, sourced from FiveThirtyEight [@FiveThirtyEightPollingData2024], contains polling information for the 2024 U.S. Presidential Election. To forecast each candidate's percentage of support, we apply Bayesian generalized linear regression to model the relationship between the support rate as the outcome variable and multiple predictor variables. This method evaluates the influence of each predictor while accounting for the effects of other variables and incorporates prior knowledge to refine predictions as new data is added. Key predictors include the polling organization, pollster quality rating, transparency score, and geographic location, with candidate support as the outcome variable and candidate name (Trump and Harris) as a feature variable. Our analysis aims to estimate candidate support and identify factors most associated with shifts in public opinion leading up to the election.

## Measurement
In our analysis of public opinion for the 2024 U.S. Presidential Election, we translate the complex and sometimes conflicting opinions of voters into a structured dataset, focusing on measurable support percentages for Trump and Harris. Polling agencies gather these opinions through surveys designed to capture representative samples, condensing each individual’s nuanced political views into a single metric of candidate support. Although this support percentage is a simplified measure, it serves as a practical outcome variable, allowing us to track shifts in candidate backing across diverse populations.

To ensure consistency and accuracy, we implemented a systematic data-cleaning process, including handling missing values, removing duplicates, filling gaps, and verifying variable formats. For instance, to enhance data transparency and quality, we retained only records with a transparency score of 5 or above and a quality rating of 2.0 or higher, filtering out low-quality or less transparent data sources to improve model reliability. We also focused on relevant variables for analysis, including pollster, quality rating, transparency score, state, candidate name, and support percentage, simplifying the data structure and emphasizing key features influencing prediction results.

To specifically focus on Trump and Harris, we further filtered the dataset to include only records for these two candidates, enabling targeted comparisons. During data standardization, missing state information was coded as "National" to clearly distinguish national polls from state-level data. This systematic data preparation not only provides a solid foundation for Bayesian generalized linear modeling but also allows us to focus on key predictors of candidate support, exploring factors with the most significant impact on public opinion and enhancing our ability to forecast election outcomes.

## Outcome variables

```{r}
#| echo: false
#| warning: false
#| label: tbl-Outcome-Table
summary_combined <- data %>%
  filter(candidate_name %in% c("Kamala Harris", "Donald Trump")) %>%
  group_by(candidate_name) %>%
  summarise(
    avg_pct = mean(pct, na.rm = TRUE),
    min_pct = min(pct, na.rm = TRUE),
    max_pct = max(pct, na.rm = TRUE)
  )

kable(summary_combined, caption = "Comparison Table of Kamala Harris and Donald Trump's Statistics")

```

@tbl-Outcome-Table displays the statistical data on the support rates (`pct`) for Kamala Harris and Donald Trump, including four metrics: candidate name, average support rate (`avg_pct`), minimum support rate (`min_pct`), and maximum support rate (`max_pct`).

For **Donald Trump**, the average support rate is 45.30%, with a minimum of 21.00% and a maximum of 70.00%. In contrast, **Kamala Harris** has an average support rate of 47.78%, with a minimum of 25.00% and a maximum of 70.00%. This indicates that, in this dataset, Kamala Harris has a slightly higher overall support rate than Donald Trump, with an average rate approximately 2.48% higher. Furthermore, her minimum support rate of 25.00% is higher than Trump’s lowest rate of 21.00%, suggesting a more stable support base at the lower end. However, their maximum support rates are the same at 70.00%, indicating that both candidates have reached similar peaks in support within this dataset.

In summary, Kamala Harris exhibits a higher average and minimum support rate compared to Donald Trump, which may imply a somewhat stronger and more consistent support base. However, these findings are limited to this sample, and further analysis with additional data would be required to draw broader conclusions.


\newpage

## Predictor variables
**numeric_grade:** A numeric rating given to the pollster to indicate their quality or reliability (e.g., 3.0).
```{r}
#| echo: false
#| warning: false
#| label: fig-Relationship-between-Candidate-Support-and-Pollster-Grade

ggplot(data, aes(x = numeric_grade, y = pct, color = candidate_name)) +
  geom_point(alpha = 0.7) +
  labs(title = "Relationship between Candidate Support and Pollster Grade", x = "Pollster Grade (numeric_grade)", y = "Support Rate (%)") +
  theme_minimal()

```
@fig-Relationship-between-Candidate-Support-and-Pollster-Grade shows the distribution of support rates for the two candidates across different pollster grades. It can be observed that support rates are more concentrated at higher grades, while they fluctuate more widely at lower grades.

\newpage

**transparency_score:** A score reflecting the pollster’s transparency about their methodology (e.g., 9.0). "A grade for how transparent a pollster is, calculated based on how much information it discloses about its polls and weighted by recency. The highest Transparency Score is 10."
```{r}
#| echo: false
#| warning: false
#| label: fig-Effect-of-Transparency-Score-on-Support

data |>
  ggplot(aes(x = transparency_score, y = pct, color = candidate_name)) +
  geom_jitter(width = 0.3, alpha = 0.7) +
  geom_smooth(method = "lm") +
  labs(
    title = "Effect of Transparency Score on Support Percentage",
    x = "Transparency Score",
    y = "Support Percentage"
  ) +
  theme_minimal() +
  scale_color_manual(values = c("#FF9999", "#66CCCC"))

```
@fig-Effect-of-Transparency-Score-on-Support illustrates the relationship between transparency score and candidate support percentage, with data points for each candidate slightly spread out horizontally for clarity. The trend lines indicate a slight positive correlation for both candidates, suggesting that higher transparency scores are generally associated with a marginal increase in support percentage. The differences in color help distinguish between the support trends of the two candidates.

\newpage

**pollster:** The name of the polling organization that conducted the poll (e.g., YouGov, RMG Research).
```{r}
#| echo: false
#| warning: false
#| label: fig-Support-by-Pollster

# Move PPIC to the first position on the x-axis
data <- data %>%
  mutate(pollster = factor(pollster, levels = c("PPIC", setdiff(levels(as.factor(pollster)), "PPIC"))))

# Plot the graph
data |>
  ggplot(aes(x = pollster, y = pct, color = candidate_name)) +
  geom_jitter(width = 0.2, alpha = 0.7) +
  labs(
    title = "Support by Pollster (Scatter Plot Showing All Observations)",
    x = "Pollster",
    y = "Support Percentage"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1), # Adjust text position
    plot.margin = margin(10, 20, 10, 10) # Add extra margin to the plot
  ) +
  scale_x_discrete(guide = guide_axis(check.overlap = TRUE)) +
  scale_color_manual(values = c("#FF9999", "#66CCCC"))




```
@fig-Support-by-Pollster illustrates a sample of support percentages for each candidate across a selection of pollsters. Due to the large number of pollsters, only a segment is displayed on the x-axis, capturing the general trend and key points. Each dot represents a poll observation, with blue and orange colors distinguishing the candidates. The spread of points highlights variability in reported support percentages, indicating that some pollsters report greater fluctuations than others. The distribution suggests that neither candidate consistently maintains higher support across the selected pollsters.


\newpage

**state:** The U.S. state where the poll was conducted or focused, if applicable.
```{r}
#| echo: false
#| warning: false
#| label: fig-Adjusted-Candidate-Support-by-State-Type

ggplot(data, aes(x = state, y = pct, fill = candidate_name)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Candidate Support by State Type", x = "State Type (state)", y = "Support Rate (%)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 8)) +  # Rotate x-axis labels and adjust font size
  scale_fill_manual(values = c("Kamala Harris" = "#66CCCC", "Donald Trump" = "#FF9999"))

```
@fig-Adjusted-Candidate-Support-by-State-Type compares the support rates of the two candidates across national and various state-specific data. It reveals significant differences in support rates among different states, reflecting the uneven distribution of candidate support across regions.

\newpage

# Model


The objective of our modelling strategy is to predict the level of support for Kamala Harris and Donald Trump in the 2024 U.S. Presidential Election using Bayesian generalized linear models. We aim to understand the relationships between polling support and various predictors, such as polling organization, state, transparency score, and pollster quality rating (numeric grade). The model details are provided in [Appendix -@sec-model-details].

We used two Bayesian regression models—one each for Kamala Harris and Donald Trump—to estimate the percentage of voters who would support them. It is important to note that the outcome variable, $pct$, represents the percentage of support for each candidate within individual polls, not the aggregated election outcome.

The models for predicting support for Kamala Harris and Donald Trump each include the following predictors: pollster, state, transparency score, and numeric grade.

The Bayesian models were fitted using the `stan_glm` function from the rstanarm package [@rstanarm] in R. The models used a Gaussian family to estimate the percentage of support, with normal priors for all parameters. The priors were specified as $\text{Normal}(0, 1)$, reflecting a weakly informative belief about the effects of each predictor.



## Model set-up

Define $pct_i$ as the predicted percentage of support for each candidate:



```{=tex}
\[
pct_i = \eta_0 + \eta_1 \cdot \text{pollster}_i + \eta_2 \cdot \text{state}_i + \eta_3 \cdot \text{transparency\_score}_i + \eta_4 \cdot \text{numeric\_grade}_i
\]


```
Where:
- $\eta_0$ is the intercept term, representing the average percentage support.
- $\eta_1, \eta_2, \eta_3, \eta_4$ are the coefficients associated with the predictors.

The priors used for the intercept and other coefficients were $\eta \sim \text{Normal}(0, 1)$, reflecting weakly informative beliefs about the effects of each predictor.



## Model justification

We expect a positive relationship between pollster quality and candidate support, as higher-quality pollsters are likely to provide more reliable estimates. Additionally, the transparency score is expected to positively influence the credibility of the poll results, contributing to higher predicted support levels. The state variable allows us to account for regional differences, and we anticipate variability between states and national polls. The pollster variable helps capture differences in polling methods and biases among organizations.
The Bayesian models were chosen for their ability to incorporate prior knowledge and quantify uncertainty in predictions, which is crucial for interpreting poll data in a dynamic electoral environment. Using pollster, state, transparency score, and pollster quality rating as predictors allowed us to account for both methodological quality and regional effects that could influence support levels for each candidate.

## Model Summary

We summarized the results from the two models using the `summary` function in R, which provides a detailed overview of the estimated coefficients and their associated uncertainty. Additionally, we used `pp_check` to perform posterior predictive checks, ensuring that the models accurately reflect the observed data. These checks showed reasonable agreement between the predicted and observed values, indicating a satisfactory model fit.

We also calculated the average predicted support for each candidate based on the fitted models. The candidate with the higher average predicted support is considered the likely winner based on the model predictions. Specifically, we found that Kamala Harris had an average predicted support of X%, while Donald Trump had an average predicted support of Y%, leading us to predict [the likely winner].



# Results

Our analysis aimed to predict the support levels for Kamala Harris and Donald Trump using Bayesian generalized linear models, taking into account key predictors such as pollster, state, transparency score, and numeric grade. Each model was fitted with $stan_glm$ using a normal prior (mean = 0, SD = 1) for all coefficients. Both models ran with 4 chains and 4000 iterations per chain, with an adapt delta of 0.95 for reliable convergence. Results are presented in tables and figures for clarity, and they are provided in [Appendix -@sec-model-details]


## Model Summary and Coefficients

For Kamala Harris, the model used **1100 observations** and **107 predictors**, producing coefficient estimates for factors such as pollster and state. Notably, some pollsters like CES/YouGov and Marist contributed positively to Harris’s predicted support, while others like Ipsos and Siena/NYT showed negative coefficients. Among state predictors, Harris’s support was highest in states like **California (mean coefficient = 5.8)** and **Maryland (mean coefficient = 5.5)**, while states like **Texas (mean coefficient = -2.4)** and **Montana (mean coefficient = -4.1)** showed lower predicted support. Transparency score also positively influenced **Harris’s predicted support (mean coefficient = 0.3)**, suggesting a favorable relationship between higher transparency and Harris’s support levels.

Donald Trump’s model, based on **2076 observations** and **125 predictors**, showed key differences. Some pollsters, including AtlasIntel and InsiderAdvantage, positively impacted Trump’s predicted support, while others, such as Ipsos and PPIC, were associated with decreased support. State-level predictors highlighted stronger support in states like **Florida (mean coefficient = 3.6)** and **Texas (mean coefficient = 2.9)**, while states like **California (mean coefficient = -7.9)** and **New York (mean coefficient = -4.2)** reflected lower predicted support. Interestingly, the transparency score negatively influenced **Trump’s predicted support (mean coefficient = -0.3)**, suggesting that Trump’s support may be less associated with higher transparency.

## Predictive Insights and Posterior Predictive Checks

Posterior predictive checks confirmed a strong fit for both models, indicating that they reliably capture the observed data trends. Average predicted support was calculated for each candidate, with Kamala Harris receiving an average predicted support of **47.34%** and Donald Trump receiving a lower average. Thus, the model’s aggregated predictions indicate **Kamala Harris as the likely candidate to secure a higher average support** in the dataset analyzed.

\newpage

## Transparency Score and Predicted Support

@fig-Transparency-Score presents a comparative analysis of both candidates' predicted support by transparency score. For Harris, higher transparency scores correlate with increased support, while Trump’s model shows a slight decline in support as transparency scores rise. In Harris's case, these trends suggest that voters may respond positively to pollsters with higher transparency scores, while Trump’s support remains less affected by this factor. This discrepancy underscores a potential contrast in voter perception of pollster transparency between the two candidates.

```{r}
#| echo: false
#| warning: false
#| message: false
#| results: "hide"
#| label: fig-Transparency-Score

just_harris_high_quality <-
  data |>
  filter(candidate_name == "Kamala Harris")

just_trump_high_quality <-
  data |>
  filter(candidate_name == "Donald Trump")

#### Fit Bayesian Models ####
# Prepare data for modeling
just_harris_high_quality <- just_harris_high_quality |>
  mutate(
    pollster = factor(pollster),
    state = factor(state)
  )

just_trump_high_quality <- just_trump_high_quality |>
  mutate(
    pollster = factor(pollster),
    state = factor(state)
  )

# Specify priors
priors <- normal(0, 1)

# Model for Kamala Harris: Predicting percentage support using key predictors
harris_model <- stan_glm(
  pct ~ pollster + state + transparency_score + numeric_grade,
  data = just_harris_high_quality,
  family = gaussian(),
  prior = priors,
  prior_intercept = priors,
  seed = 123,
  chains = 4,
  iter = 4000,
  adapt_delta = 0.95
)

# Model for Donald Trump: Predicting percentage support using key predictors
trump_model <- stan_glm(
  pct ~ pollster + state + transparency_score + numeric_grade,
  data = just_trump_high_quality,
  family = gaussian(),
  prior = priors,
  prior_intercept = priors,
  seed = 123,
  chains = 4,
  iter = 4000,
  adapt_delta = 0.95
)

combined_data <- bind_rows(
  just_harris_high_quality |>
    mutate(candidate = "Kamala Harris", fitted_pct = predict(harris_model)),
  just_trump_high_quality |>
    mutate(candidate = "Donald Trump", fitted_pct = predict(trump_model))
)
# Plot predicted support by transparency score for both candidates
fig1 <- ggplot(combined_data, aes(x = transparency_score, y = fitted_pct, color = candidate)) +
  geom_point(alpha = 0.7) +
  geom_smooth(aes(y = fitted_pct), method = "lm", se = FALSE, linetype = "dotted") +
  theme_classic() +
  labs(
    y = "Predicted Support Percentage",
    x = "Transparency Score",
    title = "Support by Transparency Score for Harris & Trump"
  ) +
  scale_color_manual(values = c("Kamala Harris" = "#66CCCC", "Donald Trump" = "#FF9999"))

# Print the plot
print(fig1)

```
@fig-Transparency-Score plots predicted support as a function of transparency score for both candidates, using points and a trend line for each candidate.

\newpage

## State-Level Support Distribution

The predicted support levels vary considerably across the selected states, as shown in @fig-Key-State. Harris’s support is strongest in traditionally Democratic-leaning states like California and Maryland, while Trump finds greater support in Republican-leaning states such as Florida and Texas. These regional differences align with historical voting patterns, adding confidence to our model's predictive validity. The chosen states – North Carolina, Wisconsin, Arizona, Maryland, Georgia, Michigan, Pennsylvania, Florida, Texas, New York, and California – represent a mix of swing states and strongholds for each party. This sample provides a balanced view of the political landscape and highlights key battleground areas for the upcoming election.


```{r}
#| echo: false
#| warning: false
#| message: false
#| results: "hide"
#| label: fig-Key-State

state_support <- combined_data |>
  group_by(state, candidate) |>
  summarize(avg_support = mean(fitted_pct), .groups = "drop")

# Retain data for key states only
key_states <- c("Florida", "Pennsylvania", "Michigan", "Wisconsin", "Arizona", 
                "Georgia", "Texas", "California", "New York", "North Carolina")

state_support_filtered <- state_support |>
  filter(state %in% key_states)

# Plot predicted support by key states only
fig2 <- ggplot(state_support_filtered, aes(x = reorder(state, avg_support), y = avg_support, fill = candidate)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(
    y = "Average Predicted Support Percentage",
    x = "State",
    title = "Predicted Support in Key States for Harris & Trump"
  ) +
  scale_fill_manual(values = c("Kamala Harris" = "#66CCCC", "Donald Trump" = "#FF9999")) +
  coord_flip() +
  theme(
    axis.text.y = element_text(size = 8)
  )

# Print the plot
print(fig2)





```
@fig-Key-State shows the average predicted support by state in a bar chart, allowing for a side-by-side comparison of Harris and Trump in sample states.



## Aggregate Prediction and Final Outcome

Based on average support, the model’s aggregate prediction indicates that Kamala Harris is expected to have higher overall support than Donald Trump, with an average predicted support of 47.34%. Given this outcome, **our model predicts Kamala Harris as the candidate more likely to win**, aligning with historical trends in states where she showed significant predicted support.


# Discussion

## Summary of Key Contributions

This paper utilizes Bayesian generalized linear models to analyze polling data for Kamala Harris and Donald Trump, focusing on the effects of pollster, state, transparency score, and numeric grade. By modelling predicted support for each candidate, we uncover how these factors shape support dynamics, with transparency score playing a notable role. This approach not only provides insight into current polling trends but also offers a framework for identifying factors that may influence public opinion in future elections.

## Insights into Voter Behavior and Polling Dynamics

significant takeaway is the relationship between transparency score and predicted support, particularly for Harris. Our model suggests that higher transparency scores positively correlate with Harris’s support, indicating that her supporters may place a higher value on reliable, open polling. Silver’s discussion on "nonresponse bias" offers a potential explanation: voters with lower civic engagement may be less likely to respond to polls, potentially skewing data towards more transparent sources that appeal to engaged voters. [@nyt_trump_harris_2024] This insight reveals a potential gap in polling that could affect both parties depending on their voter base’s engagement levels.

Furthermore, the regional distribution of support aligns with expected voting patterns. Our findings echo Silver’s point about the difficulty in predicting the direction of polling errors, particularly in battleground states. Like Silver’s model, ours shows strong geographical polarization, with Harris favoured in traditionally Democratic states and Trump showing strength in Republican states. [@nyt_trump_harris_2024] This divide underscores the importance of regional factors in understanding candidate support, even as national polling averages present a closer race.

## Limitations and Weaknesses

This analysis presents several limitations related to the Bayesian modelling approach, data quality, and the decision to build separate models for each candidate.

First, Bayesian models rely on prior assumptions and conditional independence, which may not fully capture the complexity of voter behaviour and the nuanced social-political environment. The choice of prior distributions significantly impacts predictions, and while we used a normal prior with a mean of 0 and standard deviation of 1, different priors might yield varying results. Conducting sensitivity analyses could help assess the robustness of our findings to these choices.

One important methodological limitation is our decision to use separate models for each candidate. While this approach allows us to capture candidate-specific factors and predictors that may uniquely impact each candidate’s support, it also introduces potential concerns regarding consistency. Separate models may scale predictors differently, making it difficult to interpret relative support levels on a common scale. Additionally, this approach assumes that factors influencing support for one candidate are independent of those for the other when in reality, voter preferences are often interconnected. Exploring a joint model with interaction terms could provide a more cohesive understanding of how predictors influence both candidates’ support of one another.

The quality of polling data also poses challenges. Real-time polling data often contains errors and biases that fluctuate over time, which can directly impact model accuracy. Polling data is particularly susceptible to nonresponse bias, as some voter groups are harder to reach or less likely to participate. Although we restricted our analysis to high-quality polls with strong transparency scores, this filtering may introduce selection bias by excluding potentially informative, lower-rated polls that could provide additional perspectives on voter sentiment.

Moreover, our model focuses on general trends without fully accounting for localized effects, which are often significant in election outcomes. Regional and demographic-specific dynamics are crucial in predicting support in battleground states. Without accounting for these localized effects, our model may face potential inaccuracies in areas where support is highly polarized.

Predicting election outcomes is inherently uncertain due to the unpredictability of major events, such as economic downturns or policy shifts, that can quickly alter voter sentiment. Although Bayesian modelling can account for some uncertainty, it cannot fully anticipate or quantify these changes, especially in a fast-changing environment. Additionally, our model does not account for hard-to-measure influences, such as social media dynamics, international relations, and cultural shifts, which can significantly impact election results.

Finally, while Bayesian models allow for updates with new data, election polling is particularly sensitive to real-time shifts. Rapid changes in public opinion may not be immediately reflected in the model if there is a delay in data availability, which could impact prediction accuracy closer to the election.

## Future Directions for Research

Future research could expand upon these findings by incorporating additional predictors that capture changing political dynamics, such as voter turnout expectations, economic indicators, and demographic shifts. Silver’s article highlights the importance of considering factors like the "Bradley effect" and "shy voter theory," which could be examined by integrating historical demographic trends and comparing them with current polling data. [@nyt_trump_harris_2024] Including more demographic data might reveal hidden trends within subgroups, enhancing the model's predictive power.

Another promising approach would be to experiment with a joint model that allows for shared predictors and interaction terms between the candidates. A joint structure could provide a more integrated perspective on how factors like transparency and geographic location simultaneously impact both candidates' support, reducing inconsistencies introduced by separate models.

Finally, alternative modelling techniques, such as multilevel regression with post-stratification (MRP), could offer more granular insights into support patterns across demographic and geographic subsets. Though not used in this analysis, MRP has shown success in capturing detailed trends within voter subgroups, potentially addressing some limitations related to local effects.

## Concluding Remarks

This paper demonstrates the potential of Bayesian modelling in analyzing and interpreting election polling data. By examining how factors like pollster transparency and geography influence support, we provide a foundation for understanding voter behaviour within the context of the 2024 U.S. presidential election. However, as discussed, the inherent uncertainty in election forecasting calls for ongoing data updates and methodological refinements. Future studies can build on these findings to enhance the accuracy and relevance of election forecasts, ultimately contributing to a more comprehensive understanding of the factors that drive public support.


\newpage

\appendix

# Appendix {.unnumbered}

# Marquette Law School Poll - Methodology: Probability Panel

## Overview of Marquette Law School Poll and Its Influence
The Marquette Law School Poll holds a prominent position in American politics, particularly within Wisconsin’s political landscape. As a trusted gauge of public opinion in this critical swing state, it is frequently referenced by politicians, media, and scholars for election forecasting and policy analysis [@conant2006wisconsin]. Known for its commitment to high-quality research methods and independence, the Marquette Law School Poll achieves notable credibility and influence in its data. This credibility is reinforced by its high numeric grade and transparency score, rated at 3 and 10, respectively, which imply a high level of reliability in its findings. The combination of methodological rigour and transparency strengthens the trustworthiness of its survey results, making it a valuable tool for understanding public opinion trends and informing policy discussions.

## Probability Panel Methodology
The probability panel methodology is a statistical sampling method designed to ensure both accuracy and representativeness of a sample.[@scherpenzeel2011data]  In this approach, participants are randomly selected from a verified voter database, with each individual having a known chance of being chosen. The Marquette Law School Poll employs this probability panel technique to enhance scientific rigor and capture the diversity of Wisconsin’s population across race, gender, age, and geographic location, making the sample more reflective of the population as a whole.

A key advantage of the probability panel approach is its longitudinal design, which involves repeatedly surveying the same group of participants over time. The Marquette Law School Poll uses this method to track changes in opinions and attitudes at different points, providing insights into how public views on key issues and elections evolve. This approach not only allows for current voter analysis but also provides valuable long-term insights for policy and election research, especially in critical swing states like Wisconsin.


## Sampling and Data Collection
Each survey cycle includes over 700 registered Wisconsin voters [@marquette_poll_about], who are contacted via both cell phones and landlines to maximize sample reach and inclusivity. Interviews are conducted by professional interviewers over several nights, enhancing access to a representative population by reaching individuals with varying availability. This dual-frame approach ensures the inclusion of perspectives from all eligible voters, including those who rely solely on cell phones.

## Advantages and Limitations of the Probability Panel
The probability panel methodology has notable strengths and limitations, supported by various scholarly perspectives. Through random sampling, probability panels reduce selection bias and enhance generalizability, making them robust tools for capturing statewide opinion trends. Additionally, repeated surveys with the same panel facilitate longitudinal analysis, allowing researchers to track shifts in public attitudes in response to political events and policy changes. [@bartels2000] demonstrates that repeated measures improve the predictive power of panel studies by revealing trends over time. However, panel studies have limitations; participants may experience panel conditioning, where repeated exposure influences their responses, potentially impacting data validity. Moreover, this method demands significant resources to recruit and retain a balanced panel, as dropout is common among certain demographic groups, risking the sample’s representativeness. [@warren2012] note that sustained investments are required to maintain a diverse panel, with selective dropout over time presenting a challenge for generalizable findings. These factors highlight both the advantages and constraints of probability panels in social science research.

## Comparison Between Probability Panel and Convenience Sampling:
In polling, the probability panel and convenience sampling methods offer contrasting approaches to data collection, each with unique advantages and limitations. I chose these two methods for comparison due to their distinct methodologies and how they address the trade-off between accuracy and efficiency. The probability panel method, commonly employed by highly rated pollsters, selects participants through random sampling from a target population and surveys them repeatedly over time. This method enhances generalizability by minimizing selection bias, as each participant is statistically representative of the population being studied. Additionally, its longitudinal design allows researchers to observe changes in individual opinions over time, making it particularly effective for understanding shifts in attitudes related to political events or policy changes. However, probability panels are resource-intensive, requiring substantial funding and time to recruit, manage, and retain a balanced panel. The retention of participants can be challenging, as some may drop out over time, potentially affecting the sample’s representativeness.

In contrast, convenience sampling, used by some lower-rated pollsters in this dataset, recruits participants based on ease of access and does not employ random selection. This method is often faster and more cost-effective than probability sampling, as it bypasses the need for rigorous participant selection. According to [@etikan2016], convenience sampling allows researchers to gather opinions quickly, which can be useful for preliminary insights or situations where time and resources are limited. However, the lack of randomization introduces a risk of sampling bias, as participants are self-selected or chosen based on availability, leading to potential overrepresentation or underrepresentation of certain groups. This bias limits the generalizability of the results, as findings from a convenience sample may not accurately reflect the opinions of the larger population.
In summary, probability panels are ideal for detailed, representative studies that require high accuracy, despite their resource demands. Meanwhile, convenience sampling offers an efficient alternative for quick insights but comes at the cost of reduced reliability and generalizability. Together, these methods illustrate a fundamental balance in polling between data quality and logistical efficiency, providing valuable insights depending on the study’s goals and constraints.

## Addressing Non-Response and Questionnaire Design
To address non-response, the Marquette Law School Poll employs **weighting adjustments** based on demographic characteristics such as age, gender, race, and education, correcting sample imbalances and ensuring that the final sample accurately reflects Wisconsin’s electorate. Furthermore, the questionnaire is designed to be straightforward, minimizing respondent fatigue and confusion. Nonetheless, some questions may simplify complex issues, and limited use of open-ended questions might restrict the deeper exploration of voter motivations.

## Summary and Evaluation
Through its rigorous probability panel sampling and high standards, the Marquette Law School Poll offers a comprehensive and reliable view of public opinion in Wisconsin. This approach provides valuable data on election trends and policy preferences in a pivotal swing state, enriching the understanding of public sentiment and supporting informed decision-making in American politics. 

An evaluation of the probability panel method reveals both strengths and limitations. This method provides high representativeness and accuracy by randomly selecting participants from a verified voter database, which minimizes selection bias and enhances the applicability of the results. Additionally, repeated surveys allow for valuable longitudinal analysis, offering insights into shifting public opinions over time—a crucial factor in a swing state like Wisconsin.

However, limitations exist. The panel effect may influence objectivity, as repeated participation can lead respondents to answer more consistently over time. Furthermore, maintaining a balanced panel requires substantial resources, and certain groups may gradually drop out, impacting data completeness. While weighting adjustments help address non-response, consistent underrepresentation of some groups may still affect sample comprehensiveness.

In summary, the Marquette Law School Poll’s probability panel method offers strong reliability and representativeness, making it a valuable tool for long-term public opinion analysis. Nonetheless, the resource demands and potential panel effects suggest cautious interpretation and, where possible, complementary methods to validate findings.

\newpage

# Idealized $100K Election Forecasting Methodology and Survey 

## Idealized Methodology

### Objective

Our goal is to provide an accurate, representative forecast for the 2024 U.S. presidential election by designing a high-quality survey that captures voter sentiment across key demographic and geographic segments. By addressing known polling biases and using transparent methods for aggregation, this methodology aims to produce a reliable election prediction within a $100K budget.

### Sampling Approach

We aim for a sample size of approximately 5,000 respondents, selected through **stratified random sampling** to ensure representativeness across demographic groups.

**Definition and Justification of Stratified Sampling:**
Stratified sampling is a method that divides the population into distinct subgroups, or "strata" (e.g., by age, gender, race, education, and geographic region). Within each stratum, participants are randomly sampled to ensure each subgroup is proportionally represented. This technique is particularly valuable for election forecasting, where different demographic groups exhibit varied voting behaviours [@groves2009survey].


**Strengths and Weaknesses of Stratified Sampling:**  

Stratified sampling reduces sampling error and increases the precision of estimates within each subgroup, which is particularly beneficial for capturing the opinions of smaller or more variable subgroups like non-White voters or those in swing states [@lohr2019sampling]. However, accurate population data is required to determine the appropriate strata sizes, and survey costs and complexity can increase, particularly when oversampling smaller or hard-to-reach groups.

**Sampling Simulation:**

To evaluate the effectiveness of stratified sampling, a simulation could be conducted to compare it with simple random sampling. By randomly sampling from demographic strata in previous election data, we could measure the reduction in sampling error and the improved accuracy of subgroup estimates, thus reinforcing stratified sampling's value for election forecasts.


**Stratification and Quotas:**

Each demographic quota will be weighted to reflect its proportion in the general voting population, based on recent U.S. Census data. The primary demographic strata include:

- **Age:** 18-29, 30-44, 45-64, 65+

- **Gender:** Male, Female, Non-binary/Other

- **Race/Ethnicity:** White, Black or African American, Hispanic or Latino, Asian, Other

- **Education Level:** High school or less, Some college, Bachelor's degree, Graduate degree

- **Geographic Region:** All 50 states, with oversampling in key swing states like Pennsylvania, Michigan, and Georgia.

### Recruitment Strategy

We will partner with a reputable survey panel provider, such as Ipsos or YouGov, to ensure high-quality, verified respondents. This will help us reach a diverse pool while maintaining reliability and transparency in respondent recruitment. To supplement this sample, we will target social media ads toward underrepresented demographics. Each respondent will receive a $5 incentive to encourage engagement.

**Panel Recruitment and Potential Biases:**

Using panel providers is efficient and provides access to verified respondents, but panel bias may arise as frequent survey takers might not represent the broader population [@tourangeau2013science]. To mitigate this, we will include unique respondents through targeted social media ads, especially focusing on underrepresented demographics.


### Survey Design and Implementation

The survey will be hosted on Google Forms, with a professional introduction, contact information, and clear instructions. It will be kept open for approximately 2-3 weeks, allowing sufficient time for response collection.

**Survey Structure:**

1. **Introduction and Contact Information**: An introductory message explains the survey’s purpose, assures anonymity and provides contact details for further information.

2. **Screening Questions**: To ensure eligible respondents, questions will confirm age, U.S. citizenship, and voter registration status.

3. **Core Questions**: These include demographic information, voting intentions, and issue priorities.

4. **Thank You Message**: The survey concludes with a thank-you note and contact details for any follow-up questions.

Each question will be carefully worded and ordered to maintain neutrality and flow, with an expected completion time of 5-7 minutes.

### Data Validation

To maintain data quality, we will implement the following:

- **Attention Checks**: Questions designed to identify inattentive responses.

- **Duplicate Response Prevention**: Google Forms settings will restrict multiple submissions from the same respondent.

- **Response Time Analysis**: Flagging and reviewing responses completed significantly faster than the average time to ensure thoughtful answers.

- **Post-Survey Weighting**: Adjustments based on demographic quotas ensure alignment with the U.S. population profile.

### Poll Aggregation and Forecasting Methodology

For aggregation, each poll will be weighted based on transparency score and demographic representativeness. The forecast will use a Bayesian hierarchical model to account for state-level variation, incorporating:

- **Prior Election Data**: Trends from recent election cycles.

- **Real-Time Updates**: Weekly adjustments based on new data.

- **Transparency Weighting**: Additional weight for respondents who express higher trust in transparent polling practices.

## Idealized Survey

<https://docs.google.com/forms/d/1Rr7YOXDPS4yKkB9_AlF4acuMN1swhBV2JFOgpb4PtIg/edit>


**2024 U.S. Presidential Election Voter Intentions and Key Issues Survey**

Welcome to the "2024 U.S. Presidential Election Voter Intentions and Key Issues Survey". This survey aims to gather insights into voter preferences, key concerns, and demographics to better understand the views of the American electorate as we approach the 2024 election. Your responses will remain anonymous and will contribute to a more accurate, representative forecast. The survey takes approximately 5–7 minutes to complete. Thank you for your participation! If you have any questions or concerns, please contact: jiaxuan.song@mail.utoronto.ca


 **1. Are you a U.S. citizen eligible to vote in the 2024 presidential election?** 

Yes 

No 


**2. Are you registered to vote?** 

Yes

No

Prefer not to say 


**3. Which state do you reside in?** 

Alabama

Alaska

Arizona

Arkansas

California

Colorado

Connecticut

Delaware

Florida

Georgia

Hawaii

Idaho

Illinois

Indiana

Iowa

Kansas

Kentucky

Louisiana

Maine

Maryland

Massachusetts

Michigan

Minnesota

Mississippi

Missouri

Montana

Nebraska

Nevada

New Hampshire

New Jersey

New Mexico

New York

North Carolina

North Dakota

Ohio

Oklahoma

Oregon

Pennsylvania

Rhode Island

South Carolina

South Dakota

Tennessee

Texas

Utah

Vermont

Virginia

Washington

West Virginia

Wisconsin

 Wyoming


**4. What is your age?** 

18-29 

30-44
 
45-64 

65+
 
 
**5. What is your gender?** 

Male 

Female 

Non-binary/Other 

Prefer not to say 


**6. What is your race/ethnicity?** 

White 

Black or African American 

Hispanic or Latino
 
Asian 

Other 


**7. What is the highest level of education you have completed?** 

High school or less 

Some college 

Bachelor's degree 

Graduate degree 


**8. On a scale of 1-5, how likely are you to vote in the upcoming election? ​​(Very unlikely to Very likely)** 

1 

2 

3 

4 

5 


**9. To ensure quality, please select “Somewhat disagree” as your answer to this question.**

Strongly agree

Somewhat agree

Neutral

Somewhat disagree

Strongly disagree


**10. If the election were held today, which candidate would you most likely support?** 

Kamala Harris (Democrat) 

Donald Trump (Republican)

Other (please specify)

Undecided 


**11. If you choose "Other" in the previous question, please specify the person you most likely to support.**



**12. What issues are most important to you in this election? (Select up to 3)** 

Economy 

Healthcare 

Climate change 

Education 

Immigration 

Foreign policy 

Other (please specify) 


**13. How satisfied are you with the current direction of the U.S. government? (Very dissatisfied to Very satisfied)** 

1

2

3

4

5


**14. How much do you trust the accuracy of public opinion polls? (Highly distrust to Highly trust)** 

1

2

3

4

5


**15. Have you previously participated in political opinion polls?** 

Yes 

No


**Thank You!**

Thank you for participating in this survey! Your responses are valuable to our research. If you have any questions or would like more information, please contact: Jiaxuan.song@mail.utoronto.ca

\newpage

# Model Details {#sec-model-details}

## Summary of Harris model

```{r}
#| echo: false
#| warning: false
#| message: false
summary(harris_model)
```

\newpage
The model summary for Kamala Harris displays the estimates of coefficients for various predictors, including pollster, state, transparency score, and numeric grade. It provides insight into how each factor contributes to predicting support for Harris in the 2024 election.

## Summary of Trump model
```{r}
#| echo: false
#| warning: false
#| message: false

summary(trump_model)
```


The model summary for Donald Trump displays the estimates of coefficients for various predictors, including pollster, state, transparency score, and numeric grade. It provides insight into how each factor contributes to predicting support for Harris in the 2024 election.

## Posterior predictive checks

### Posterior predictive checks for Harris model
```{r}
#| echo: false
#| warning: false
#| message: false
#| results: "hide"
pp_check(harris_model)
```
The posterior predictive check (pp_check) for Kamala Harris's model visually compares the model-generated predictions to the actual observed values, assessing the model's fit and reliability.

### Posterior predictive checks for Trump model

```{r}
#| echo: false
#| warning: false
#| message: false
#| results: "hide"
pp_check(trump_model)
```
The posterior predictive check (pp_check) for Donald Trump's model visually compares the model-generated predictions to the actual observed values, assessing the model's fit and reliability.
\newpage

# References
